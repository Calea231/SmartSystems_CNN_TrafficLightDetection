{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smart_Systems_Sample_Solution_Chapter_4_ImageWoof_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "73JyIADeWCtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Smart_Systems_Sample_Solution_Chapter_4_ImageWoof_dataset.ipynb\"\"\"\n",
        "\n",
        "__author__ = \"Marius Landmann\"\n",
        "\n",
        "\n",
        "\"Main source: https://open.hpi.de/courses/neuralnets2020\"\n",
        "\"Other sources which helped writing the code: https://github.com/MariusLandmann/SmartSystems_CNN_TrafficLightDetection/blob/master/Sources/Links.docx\"\n",
        "\n",
        "# TensorFlow â‰¥2.0 is required\n",
        "%tensorflow_version 2.x\n",
        "!pip install --upgrade deeplearning2020\n",
        "!pip install tensorflow_datasets\n",
        "!pip install --upgrade tensorflow_datasets\n",
        "!pip install tfds-nightly\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "#Needs the provided GPU from Colab -> test if it is used\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "\n",
        "##Import required tools, layer types\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Activation, Input, \\\n",
        "  Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "import gzip\n",
        "from deeplearning2020 import helpers \n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "!pip install h5py pyyaml\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import os\n",
        "# !pip install absl-py\n",
        "# from absl import app\n",
        "# from absl import flags\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXx5ELF0X3DZ",
        "colab_type": "text"
      },
      "source": [
        "# Cloning and Pulling the GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "977mUtSWWt84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Forked repository\n",
        "repo_url = 'https://github.com/MariusLandmann/SmartSystems_CNN_TrafficLightDetection'\n",
        "\n",
        "\n",
        "#Clone repository\n",
        "\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "\n",
        "print('Pull it so that we have the latest code/data')\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTUQd_SBYXN6",
        "colab_type": "text"
      },
      "source": [
        "# Loading the Dataset\n",
        "& preprocessing it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrvqV-RbF1tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeplearning2020.datasets import ImageWoof\n",
        "train_data, test_data, classes= ImageWoof.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agsmnFa7E3Pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reshape and shuffle the dataset\n",
        "def preprocess(image, label):\n",
        "    resized_image = tf.image.resize(image, [300, 300])\n",
        "    return resized_image, label\n",
        "\n",
        "batch_size = 32\n",
        "print('shape of training data before preprocessing: ', train_data)\n",
        "train_data = train_data.shuffle(1000)\n",
        "\n",
        "\n",
        "train_data = train_data.map(preprocess) \\\n",
        "  .batch(batch_size).prefetch(1)\n",
        "test_data = test_data.map(preprocess) \\\n",
        "  .batch(batch_size).prefetch(1)\n",
        "print('shape of training data after preprocessing: ', train_data)\n",
        "print('shape of test data after preprocessing: ', test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3byRBOZeZR6",
        "colab_type": "text"
      },
      "source": [
        "# Architecture, Training and Evaluation of the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJkP-UITGH2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### model architecture\n",
        "learning_rate=0.001\n",
        "momentum=0.9\n",
        "dense_neurons=300\n",
        "a_filters=128\n",
        "b_filters=256\n",
        "first_kernel_size=(7,7)\n",
        "n_kernel_size=(3,3)\n",
        "\n",
        "activation='elu'\n",
        "\n",
        "\n",
        "# input size of images must be 300x300 with RGB color\n",
        "input_layer = Input(shape=(300, 300, 3))\n",
        "\n",
        "## Layerstructure\n",
        "# Convolutional Layers with Max Pooling\n",
        "model = Conv2D(filters=a_filters, kernel_size=first_kernel_size, activation=activation)(input_layer)\n",
        "model = MaxPooling2D((2,2))(model)\n",
        "\n",
        "model = Conv2D(filters = a_filters, kernel_size=n_kernel_size, activation=activation)(model)\n",
        "model = MaxPooling2D((2,2))(model)\n",
        "\n",
        "model = Conv2D(filters = b_filters, kernel_size=n_kernel_size, activation=activation)(model)\n",
        "model = MaxPooling2D((2,2))(model)\n",
        "\n",
        "model = Conv2D(filters = b_filters, kernel_size=n_kernel_size, activation=activation)(model)\n",
        "model = MaxPooling2D((2,2))(model)\n",
        "\n",
        "\n",
        "model = Conv2D(filters = b_filters, kernel_size=n_kernel_size, activation=activation, padding='same')(model)\n",
        "model = MaxPooling2D((2,2))(model)\n",
        "\n",
        "model = Conv2D(filters = b_filters, kernel_size=n_kernel_size, activation=activation, padding='same')(model)\n",
        "model = MaxPooling2D((2,2))(model)\n",
        "\n",
        "\n",
        "\n",
        "model = Conv2D(filters = b_filters, kernel_size=n_kernel_size, activation=activation, padding='same')(model)\n",
        "# model = Conv2D(filters = b_filters, kernel_size=n_kernel_size, activation=activation, padding='same')(model)\n",
        "# model = Conv2D(filters = b_filters, kernel_size=n_kernel_size, activation=activation, padding='same')(model)\n",
        "\n",
        "# Fully-Connected-Classifier\n",
        "model = Flatten()(model)\n",
        "model = Dense(dense_neurons, activation=activation)(model)\n",
        "\n",
        "model = Dense(dense_neurons / 2, activation='tanh')(model)\n",
        "\n",
        "# Output Layer\n",
        "output = Dense(10, activation=\"softmax\")(model)\n",
        "\n",
        "model = Model(input_layer, output)\n",
        "\n",
        "# Compiling model\n",
        "optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=momentum)\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC1k70WkGXAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=13,\n",
        "    validation_data = test_data\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkQmUNFnWWUi",
        "colab_type": "text"
      },
      "source": [
        "# Saving and Recreating the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEdLryJYOwJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Save the whole model\n",
        "model.save('./trained_CNN/imagewoof/my_model_imagewoof.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdZPdL9F46mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Recreate whole model\n",
        "new_model=keras.models.load_model('./trained_CNN/imagewoof/my_model_imagewoof.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4wW0YfdZA4v",
        "colab_type": "text"
      },
      "source": [
        "# DOWNLOAD created files\n",
        "In this case downloading the previously created model.\n",
        "\n",
        "Steps for downloading files manually: Anzeigen -> Inhalt -> Dateien (you can also display and download everything generated)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1pv_nWrWzQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD created files (in this case the previously created model) #################\n",
        "from google.colab import files\n",
        "files.download('./trained_CNN/imagewoof/my_model_imagewoof.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}