{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smart_Systems_Sample_Solution_Chapter_3_fashion_datasets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "73JyIADeWCtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Smart_Systems_Sample_Solution_Chapter_3_fashion_datasets.ipynb\"\"\"\n",
        "\n",
        "__author__ = \"Marius Landmann\"\n",
        "\n",
        "\"Other sources which helped writing the code: https://github.com/MariusLandmann/SmartSystems_CNN_TrafficLightDetection/blob/master/Sources/Links.docx\"\n",
        "\n",
        "# TensorFlow â‰¥2.0 is required\n",
        "%tensorflow_version 2.x\n",
        "!pip install --upgrade deeplearning2020\n",
        "!pip install tensorflow_datasets\n",
        "!pip install --upgrade tensorflow_datasets\n",
        "!pip install tfds-nightly\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "#Needs the provided GPU from Colab -> test if it is used\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "\n",
        "##Import required tools, layer types\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Dense, Activation, Input, \\\n",
        "  Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "import gzip\n",
        "from deeplearning2020 import helpers \n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "!pip install h5py pyyaml\n",
        "from __future__ import absolute_import, division, print_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXx5ELF0X3DZ",
        "colab_type": "text"
      },
      "source": [
        "# Cloning and Pulling the GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "977mUtSWWt84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Forked repository\n",
        "repo_url = 'https://github.com/MariusLandmann/SmartSystems_CNN_TrafficLightDetection'\n",
        "\n",
        "\n",
        "# Clone repository\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "\n",
        "print('Pull it')\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTUQd_SBYXN6",
        "colab_type": "text"
      },
      "source": [
        "# Loading the Dataset\n",
        "& unzipping it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuWx66GC1GoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###mnist_reader -> needed for loading the dataset (https://www.coursehero.com/file/49430530/util-mnist-readerpy/)\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "#Unzip \n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3inaP_82Zds2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Loading the data with Python\n",
        "X_train, y_train = load_mnist('dataset_FASHION', kind='train')\n",
        "X_test, y_test = load_mnist('dataset_FASHION', kind='t10k')\n",
        "## X: images; y: labels\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO5pEdScZ-bb",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRSfJ4hrs99P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reshape dataset\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7tEJs1aVCOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Normalize the pixel values\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuYkBXBjt8LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Convert number to a vector --> necessary for the chosen models\n",
        "total_classes = 10\n",
        "train_vec_labels = keras.utils.to_categorical(y_train, total_classes)\n",
        "test_vec_labels = keras.utils.to_categorical(y_test, total_classes)\n",
        "\n",
        "\n",
        "print('train labels', y_train.shape)\n",
        "print('test labels', y_test.shape)\n",
        "\n",
        "print('train labels vector', train_vec_labels.shape)\n",
        "print('test labels vector', test_vec_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bQBdQGRair0",
        "colab_type": "text"
      },
      "source": [
        "# Models with Different Activation Functions and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcmSu8NC2TIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Model with tanh\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "model_tanh = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    keras.layers.Dense(128, activation='tanh'),\n",
        "    keras.layers.Dense(10, activation='tanh')\n",
        "])\n",
        "\n",
        "models = [model_tanh]\n",
        "\n",
        "[\n",
        "  model.compile(\n",
        "      optimizer='sgd',\n",
        "      loss='mean_squared_error',\n",
        "      metrics=['accuracy']\n",
        "  ) for model in models\n",
        "]\n",
        "\n",
        "\n",
        "def create_model_tanh():\n",
        "\n",
        "  model_tanh\n",
        "  return model_tanh\n",
        "  return models\n",
        "\n",
        "\n",
        "model=create_model_tanh()\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "## Training\n",
        "epochs=20\n",
        "[\n",
        " model.fit(\n",
        "    X_train,\n",
        "    train_vec_labels,\n",
        "    epochs=epochs,\n",
        "    verbose=True\n",
        "  ) for model in models\n",
        "]\n",
        "\n",
        "\n",
        "## Evaluation with the test data (new pictures)\n",
        "_, result_tanh = model_tanh.evaluate(X_test, test_vec_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCzyRpfkYBok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Model with sgd\n",
        "\n",
        "model_sgd = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "models = [model_sgd]\n",
        "\n",
        "[\n",
        "  model.compile(\n",
        "      optimizer='sgd',\n",
        "      loss='mean_squared_error',\n",
        "      metrics=['accuracy']\n",
        "  ) for model in models\n",
        "]\n",
        "\n",
        "def create_model_sgd():\n",
        "\n",
        "  model_sgd\n",
        "  return model_sgd\n",
        "  return models\n",
        "\n",
        "\n",
        "model=create_model_sgd()\n",
        "model.summary()\n",
        "\n",
        "\n",
        "## Training\n",
        "epochs=20\n",
        "[\n",
        " model.fit(\n",
        "    X_train,\n",
        "    train_vec_labels,\n",
        "    epochs=epochs,\n",
        "    verbose=True\n",
        "  ) for model in models\n",
        "]\n",
        "\n",
        "\n",
        "## Evaluation with the test data (new pictures)\n",
        "_, result_sgd = model_sgd.evaluate(X_test, test_vec_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOyqLq0ZGss-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Model with Adam\n",
        "model_adam = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "models = [model_adam]\n",
        "\n",
        "[\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='mean_squared_error',\n",
        "      metrics=['accuracy']\n",
        "  ) for model in models\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_model_adam():\n",
        "\n",
        "  model_adam\n",
        "  return model_adam\n",
        "  return models\n",
        "\n",
        "\n",
        "model=create_model_adam()\n",
        "model.summary()\n",
        "\n",
        "\n",
        "## Training\n",
        "epochs=20\n",
        "[\n",
        " model.fit(\n",
        "    X_train,\n",
        "    train_vec_labels,\n",
        "    epochs=epochs,\n",
        "    verbose=True\n",
        "  ) for model in models\n",
        "]\n",
        "\n",
        " \n",
        "## Evaluation with the test data (new pictures)\n",
        "_, result_adam = model_adam.evaluate(X_test, test_vec_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BnWp7sBaXG7g"
      },
      "source": [
        "# Saving and Recreating the Trained Model\n",
        "Actually not necessary for such simple neurol networks, because the training is very fast. But very useful for CNNs with training phases of several hours/ several days."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rapesYNOXBFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Save the whole model\n",
        "model.save('./trained_CNN/fashion_MNIST/my_model_adam.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdZPdL9F46mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Recreate whole model\n",
        "new_model=keras.models.load_model('./trained_CNN/fashion_MNIST/my_model_adam.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4wW0YfdZA4v",
        "colab_type": "text"
      },
      "source": [
        "# DOWNLOAD created files\n",
        "In this case downloading the previously created adam model.\n",
        "\n",
        "Steps for downloading files manually: Anzeigen -> Inhalt -> Dateien (you can also display and download everything generated)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px7HzUo-bBCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./trained_CNN/fashion_MNIST/my_model_adam.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfY-VsxnacQJ",
        "colab_type": "text"
      },
      "source": [
        "# Unzip compressed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVQDUlCZMltU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Unzip CSV data (Zip) and assign them to variables\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/SmartSystems_CNN_TrafficLightDetection/dataset_FASHION/in_csv/test_compressed_fashion-mnist_test.csv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/SmartSystems_CNN_TrafficLightDetection/dataset_FASHION/in_csv')\n",
        "\n",
        "test_csv = '/content/SmartSystems_CNN_TrafficLightDetection/dataset_FASHION/in_csv/fashion-mnist_test.csv'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile('/content/SmartSystems_CNN_TrafficLightDetection/dataset_FASHION/in_csv/train_compressed_fashion-mnist_train.csv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/SmartSystems_CNN_TrafficLightDetection/dataset_FASHION/in_csv')\n",
        "\n",
        "train_csv = '/content/SmartSystems_CNN_TrafficLightDetection/dataset_FASHION/in_csv/fashion-mnist_train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2l1A5P0BNxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat {test_csv}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}